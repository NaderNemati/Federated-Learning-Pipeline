{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install Prerequisites and Dependencies"
      ],
      "metadata": {
        "id": "XGm7_xUbiaf6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stYBrClJiZkP"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision ray flwr hydra-core omegaconf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U flwr[simulation]"
      ],
      "metadata": {
        "id": "zzTx8x5iiq7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration via base.yaml:\n",
        "\n",
        "The **'conf/base.yaml'** file contains essential configurations for the federated learning pipeline. It allows you to easily modify important parameters before running the simulation, such as:"
      ],
      "metadata": {
        "id": "f0x7nUBbi2RO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample configuration (from your base.yaml file)\n",
        "cfg = {\n",
        "    'num_rounds': 3,\n",
        "    'num_clients': 5,\n",
        "    'batch_size': 32,\n",
        "    'num_classes': 10,\n",
        "    'num_clients_per_round_fit': 5,\n",
        "    'num_clients_per_round_eval': 5,\n",
        "    'config_fit': {\n",
        "        'lr': 0.001,\n",
        "        'weight_decay': 1e-4,\n",
        "        'local_epochs': 2,\n",
        "        'batch_size': 32,\n",
        "        'clip_value': 1.0,\n",
        "        'momentum': 0.9,\n",
        "    },\n",
        "    'dp': {\n",
        "        'epsilon': 1.0,\n",
        "        'delta': 1e-5,\n",
        "        'noise_scale': 0.01\n",
        "    },\n",
        "    'client_resources': {\n",
        "        'num_cpus': 1,    # Reduce CPU usage per client\n",
        "        'num_gpus': 0.0   # Disable GPU usage if not available in Colab\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "QjbdsEL4iuRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Preparation (dataset.py):\n",
        "\n",
        "This script loads and partitions the MNIST and CIFAR10 datasets, applying transformations like normalization and ensuring that data is split among clients. Each client trains its model on its data without sharing it, adhering to federated learning principles."
      ],
      "metadata": {
        "id": "mWX7AHVOjQJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "dataset.py:\n",
        "This script takes care of loading datasets and splitting them up for our federated learning setup.\n",
        "The goal here is to support both MNIST and CIFAR10, apply some useful transformations (like normalization),\n",
        "and then split the data among multiple clients. This is crucial because, in federated learning,\n",
        "clients train models on their own data without sharing it directly, so data preparation is essential.\n",
        "'''\n",
        "import torch\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "from torchvision.datasets import MNIST, CIFAR10\n",
        "from torchvision.transforms import ToTensor, Normalize, Compose, RandomHorizontalFlip, RandomCrop\n",
        "\n",
        "\n",
        "\n",
        "def get_dataset(dataset_choice: str, data_path: str = './data'):\n",
        "    \"\"\"\n",
        "    Loads the dataset the user selects (either MNIST or CIFAR10) with proper transformations.\n",
        "\n",
        "    Arguments:\n",
        "        dataset_choice (str): The dataset to load ('mnist' or 'cifar10').\n",
        "        data_path (str): Where to store the dataset.\n",
        "\n",
        "    Returns:\n",
        "        Tuple: A tuple containing the training and test datasets.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If the dataset_choice isn't 'mnist' or 'cifar10'.\n",
        "\n",
        "    Using this function, we can preprocess MNIST and CIFAR10 in different ways. For example, MNIST is grayscale, so it gets simple normalization,\n",
        "    while CIFAR10 gets a bit more fancy treatment with things like random horizontal flips and cropping to make the model more robust.\n",
        "    \"\"\"\n",
        "\n",
        "    if dataset_choice == 'mnist':\n",
        "        # MNIST is pretty straightforward. We convert the images to tensors and normalize them.\n",
        "        transform = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n",
        "        trainset = MNIST(data_path, train=True, download=True, transform=transform)\n",
        "        testset = MNIST(data_path, train=False, download=True, transform=transform)\n",
        "\n",
        "    elif dataset_choice == 'cifar10':\n",
        "        # Training CIFAR10 includes some extra augmentations to improve generalization and proficiency\n",
        "        transform_train = Compose([\n",
        "            RandomHorizontalFlip(),                             # Randomly flip the image horizontally\n",
        "            RandomCrop(32, padding=4),                          # Crop and pad to simulate data variability\n",
        "            ToTensor(),\n",
        "            Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))         # Normalization of RGB channels\n",
        "        ])\n",
        "\n",
        "        # There is no need to augment the test set, and normalization is the only processing step.\n",
        "        transform_test = Compose([\n",
        "            ToTensor(),\n",
        "            Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "\n",
        "        trainset = CIFAR10(data_path, train=True, download=True, transform=transform_train)\n",
        "        testset = CIFAR10(data_path, train=False, download=True, transform=transform_test)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported dataset: {dataset_choice}. Please choose either 'mnist' or 'cifar10'.\")\n",
        "\n",
        "    return trainset, testset\n",
        "\n",
        "\n",
        "\n",
        "def prepare_dataset(num_partitions: int, batch_size: int, dataset_choice: str, val_ratio: float = 0.1):\n",
        "    \"\"\"\n",
        "    Prepares the dataset for federated learning by splitting it into multiple partitions (clients).\n",
        "\n",
        "    Arguments:\n",
        "        num_partitions (int): Number of clients (partitions) to split the training data into.\n",
        "        batch_size (int): Batch size to use for the data loaders.\n",
        "        dataset_choice (str): The dataset choice ('mnist' or 'cifar10').\n",
        "        val_ratio (float): Each client should use 10% of data for validation\n",
        "\n",
        "    Returns:\n",
        "        Tuple: A tuple containing data loaders for training, validation, and testing.\n",
        "\n",
        "        Data is divided between clients using the IID method (Independent and Identically Distributed).\n",
        "        Due to the fact that our dataset comes from a larger pool with the same distribution (such as MNIST or CIFAR10),\n",
        "        we assume that the data drawn from each client is also drawn from the same distribution. Based on the law of large numbers,\n",
        "        each client's data represents the overall dataset fairly. Therefore, the IID method must be used to divide the data in order to maintain\n",
        "        this consistency and make sure that all clients are trained on the same global data.\n",
        "    \"\"\"\n",
        "\n",
        "    # Loading the dataset based on what the user chose (either MNIST or CIFAR10).\n",
        "    trainset, testset = get_dataset(dataset_choice)\n",
        "\n",
        "    # Spliting the training set into 'num_partitions' (one for each client).\n",
        "    num_images = len(trainset) // num_partitions\n",
        "    partition_len = [num_images] * num_partitions                   # Ensure that all clients get the same amount of data.\n",
        "\n",
        "    # Randomly splitting the training data among the clients.\n",
        "    trainsets = random_split(trainset, partition_len, torch.Generator().manual_seed(2024))\n",
        "\n",
        "\n",
        "    trainloaders = []\n",
        "    valloaders = []\n",
        "\n",
        "    # Splitting related part of the data further into training and validation sets for each client.\n",
        "    for trainset_ in trainsets:\n",
        "        num_total = len(trainset_)\n",
        "        num_val = int(val_ratio * num_total)\n",
        "        num_train = num_total - num_val\n",
        "\n",
        "        for_train, for_val = random_split(trainset_, [num_train, num_val], torch.Generator().manual_seed(2024))\n",
        "\n",
        "        # Appending data loaders for both training and validation sets to their respective lists.\n",
        "        trainloaders.append(DataLoader(for_train, batch_size=batch_size, shuffle=True, num_workers=2))\n",
        "        valloaders.append(DataLoader(for_val, batch_size=batch_size, shuffle=False, num_workers=2))\n",
        "\n",
        "    # Creation of the test loader for the test set (which is shared by all clients).\n",
        "    # The test set is kept in its original size and used after aggregation to evaluate the global model.\n",
        "    testloaders = DataLoader(testset, batch_size=128)\n",
        "\n",
        "    return trainloaders, valloaders, testloaders\n"
      ],
      "metadata": {
        "id": "ENTw9NjKjaJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Definition (model.py):\n",
        "\n",
        "Defines flexible model architectures for MNIST and CIFAR10. Based on the selected dataset, an appropriate model is dynamically initialized. This script also handles optimization, loss calculation, and evaluation, enabling seamless switching between datasets and models."
      ],
      "metadata": {
        "id": "QjWRjTlPjdvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "model.py\n",
        "The script defines the models we use for the MNIST and CIFAR10 datasets.\n",
        "The appropriate model architecture is dynamically selected and initialized based on the dataset being used.\n",
        "As part of our training and testing functions, we also handle optimization, loss calculation, and evaluation.\n",
        "We can easily switch between datasets and models with this code because it is designed to be flexible.\n",
        "'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# MNIST Model Definition\n",
        "class MNISTNet(nn.Module):\n",
        "    def __init__(self, num_classes: int) -> None:\n",
        "        super(MNISTNet, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 32, 5)       # Initial convolutional layers based on grayscale MNIST images (1 channel), 32 filters, 5x5 kernels\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
        "        self.fc1 = nn.Linear(64 * 4 * 4, 120)  # Fully connected layers for classification\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, num_classes)  # Output layer with 10 neurons, number of classes for MNIST\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 4 * 4)              # Flatten the output from the conv layers to feed into fully connected layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)                         # No activation on the final layer (since we use softmax in the loss function)\n",
        "        return x\n",
        "\n",
        "# CIFAR10 Model Definition (CIFAR10 images are RGB, so we have 3 input channels. The network here is deeper than the MNIST model.)\n",
        "class CIFAR10Net(nn.Module):\n",
        "    def __init__(self, num_classes: int) -> None:\n",
        "        super(CIFAR10Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)  # 64 filters, 3x3 kernel size, padding to keep image size the same\n",
        "        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(64)         # Batch normalization helps with training stability and convergence\n",
        "        self.batch_norm2 = nn.BatchNorm2d(128)\n",
        "        self.batch_norm3 = nn.BatchNorm2d(256)\n",
        "        self.fc1 = nn.Linear(256 * 4 * 4, 512)          # Fully connected layers for classification\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)                  # Dropout to prevent overfitting\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.batch_norm1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.batch_norm2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.batch_norm3(self.conv3(x))))\n",
        "        x = x.view(-1, 256 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)                              # No activation on the final layer (since we use softmax in the loss function)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Function to get the appropriate model based on dataset choice\n",
        "def get_model(dataset_choice: str, num_classes: int):\n",
        "    \"\"\"\n",
        "    Returns the model corresponding to the dataset being used (MNIST or CIFAR10).\n",
        "\n",
        "    Arguments:\n",
        "        dataset_choice (str): The dataset we're working with ('mnist' or 'cifar10').\n",
        "        num_classes (int): The number of output classes (10 for both MNIST and CIFAR10).\n",
        "\n",
        "    Returns:\n",
        "        torch.nn.Module: The appropriate model (either MNISTNet or CIFAR10Net).\n",
        "    \"\"\"\n",
        "    if dataset_choice.lower() == \"mnist\":\n",
        "        return MNISTNet(num_classes)\n",
        "    elif dataset_choice.lower() == \"cifar10\":\n",
        "        return CIFAR10Net(num_classes)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown dataset: {dataset_choice}. Please choose either 'mnist' or 'cifar10'.\")\n",
        "\n",
        "# Training function\n",
        "def train(net, trainloader, optimizer, epochs, device: str, clip_value=None):\n",
        "    \"\"\"\n",
        "    Trains the given network using the specified training data loader and optimizer.\n",
        "\n",
        "    Arguments:\n",
        "        net: The neural network model to train.\n",
        "        trainloader: Providing batches of training data.\n",
        "        optimizer: The optimizer for training (AdamW is used in this project).\n",
        "        epochs: The number of epochs to train for.\n",
        "        device (str): The device to run the training on ('cpu' or 'gpu').\n",
        "        clip_value: The value for gradient clipping to prevent exploding gradients. This is optional\n",
        "\n",
        "    Returns:\n",
        "        avg_loss: The average loss over the training set.\n",
        "        accuracy: The accuracy of the model on the training data.\n",
        "    \"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()             # Standard loss function for classification\n",
        "    net.train()\n",
        "    net.to(device)\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for _ in range(epochs):\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(device), labels.to(device)  # Move data to the selected device\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "\n",
        "            # For CIFAR-10 image classification, gradient clipping is crucial as it prevents exploding gradients, stabilizes training, and ensures controlled weight updates.\n",
        "            if clip_value is not None:\n",
        "                torch.nn.utils.clip_grad_norm_(net.parameters(), clip_value)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    avg_loss = total_loss / len(trainloader)\n",
        "\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "# Testing function\n",
        "def test(net, testloader, device: str):\n",
        "    \"\"\"\n",
        "    Evaluates the model's performance on the test set.\n",
        "\n",
        "    Args:\n",
        "        net: The trained neural network model to evaluate.\n",
        "        testloader: DataLoader providing batches of test data.\n",
        "        device (str): The device to run the evaluation on ('cpu' or 'cuda').\n",
        "\n",
        "    Returns:\n",
        "        loss: The total loss on the test set.\n",
        "        accuracy: The accuracy of the model on the test data.\n",
        "    \"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()                     # Loss function for classification\n",
        "    correct = 0\n",
        "    loss = 0.0\n",
        "    net.eval()\n",
        "    net.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / len(testloader.dataset)\n",
        "    return loss, accuracy\n"
      ],
      "metadata": {
        "id": "cabuSR5cjjBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Client Setup (client.py):\n",
        "\n",
        "Manages local training and evaluation on each client through the FlowerClient class. Each client is dynamically initialized, trains on its partitioned data, and incorporates Differential Privacy (DP) to protect data by adding noise to updates before they are sent to the server."
      ],
      "metadata": {
        "id": "2bWP2i_ejoou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# client.py\n",
        "This script defines the FlowerClient class, which is responsible for managing the local training and evaluation on each client.\n",
        "In addition, it ensures that each client is correctly initialized, receives updates from the server, and utilizes differential privacy\n",
        "techniques to protect the data. Additionally, each client is generated dynamically and initialized only once.\n",
        "'''\n",
        "import torch\n",
        "import flwr as fl\n",
        "from typing import Dict\n",
        "from flwr.common import NDArrays, Scalar, Context\n",
        "#from model import MNISTNet, CIFAR10Net, train, test\n",
        "import logging\n",
        "import numpy as np\n",
        "\n",
        "# Setting up loggig up important information like initialization, training, and evaluation\n",
        "logging.basicConfig(level=logging.INFO, format='[%(asctime)s] [%(levelname)s] [%(name)s] - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "initialized_clients = set()               # This set help initializ clients to avoid accidentally re-initializing the same client\n",
        "\n",
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, trainloader, valloader, num_classes, dataset_choice, client_id, epsilon=0.1, delta=1e-5, noise_scale=0.01) -> None:\n",
        "        \"\"\"\n",
        "        Initializes the client for federated learning with differential privacy settings.\n",
        "\n",
        "        Arguments:\n",
        "            trainloader: DataLoader for training data.\n",
        "            valloader: DataLoader for validation data.\n",
        "            num_classes: Number of output classes (10 for MNIST or CIFAR-10).\n",
        "            dataset_choice: The dataset being used (MNIST or CIFAR10).\n",
        "            client_id: Unique ID for each client.\n",
        "            epsilon: Privacy budget for DP.\n",
        "            delta: Privacy tolerance for DP.\n",
        "            noise_scale: Scale of noise added for DP.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "        self.dataset_choice = dataset_choice\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.client_id = client_id\n",
        "        self.epsilon = epsilon\n",
        "        self.delta = delta\n",
        "        self.noise_scale = noise_scale\n",
        "\n",
        "        # Choose the appropriate model based on the dataset (MNIST or CIFAR10)\n",
        "        if self.dataset_choice == \"mnist\":\n",
        "            self.model = MNISTNet(num_classes=num_classes)\n",
        "        else:\n",
        "            self.model = CIFAR10Net(num_classes=num_classes)\n",
        "\n",
        "        self.model.to(self.device)                  # Move the model to the appropriate device (GPU or CPU)\n",
        "\n",
        "        if self.client_id in initialized_clients:   # Check if this client has already been initialized; if yes, skip initialization\n",
        "            logger.warning(f\"[Client {self.client_id}] already initialized, skipping.\")\n",
        "        else:\n",
        "            initialized_clients.add(self.client_id)\n",
        "            logger.info(f\"[Client {self.client_id}] Initialized with DP settings (ε={self.epsilon}, δ={self.delta}, noise_scale={self.noise_scale})\")\n",
        "\n",
        "\n",
        "    def set_parameters(self, parameters: NDArrays):\n",
        "        \"\"\"Sets the model parameters received from the server.\"\"\"\n",
        "\n",
        "        params_dict = self.model.state_dict()  # Get the model's parameters\n",
        "\n",
        "        for i, key in enumerate(params_dict.keys()):\n",
        "            params_dict[key] = torch.tensor(parameters[i], dtype=params_dict[key].dtype).to(self.device)\n",
        "        self.model.load_state_dict(params_dict, strict=True)\n",
        "\n",
        "\n",
        "    def get_parameters(self, config: Dict[str, Scalar]) -> NDArrays:\n",
        "        \"\"\"Gets the model parameters to send back to the server.\"\"\"\n",
        "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]  # Convert parameters to NumPy arrays\n",
        "\n",
        "\n",
        "    def fit(self, parameters: NDArrays, config: Dict[str, Scalar]):\n",
        "        \"\"\"Trains the model using the current parameters and returns the updated parameters.\"\"\"\n",
        "\n",
        "        self.set_parameters(parameters)         # Set the model parameters received from the server\n",
        "\n",
        "\n",
        "        lr = config.get('lr', 0.001)            # Set training configurations\n",
        "        weight_decay = config.get('weight_decay', 1e-4)\n",
        "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "        epochs = config.get('local_epochs', 1)\n",
        "        clip_value = config.get('clip_value', 1)\n",
        "\n",
        "        # Training the model\n",
        "        train_loss, train_accuracy = train(self.model, self.trainloader, optimizer, epochs, self.device)\n",
        "\n",
        "\n",
        "        # Apply differential privacy to the model's parameters before sending them to the server\n",
        "        dp_parameters = self.apply_differential_privacy(self.model.state_dict())\n",
        "\n",
        "\n",
        "        # Logging that DP has been applied with specific settings\n",
        "        logger.info(f\"[Client {self.client_id}] Applied Differential Privacy (ε={self.epsilon}, δ={self.delta})\")\n",
        "\n",
        "\n",
        "        return [dp_parameters[key].cpu().numpy() for key in dp_parameters], len(self.trainloader), {\"loss\": train_loss, \"accuracy\": train_accuracy}\n",
        "\n",
        "\n",
        "    def apply_differential_privacy(self, state_dict):\n",
        "        \"\"\"Adds noise to the model parameters to ensure differential privacy.\"\"\"\n",
        "\n",
        "        dp_parameters = {}\n",
        "        for name, param in state_dict.items():\n",
        "            if param.dtype == torch.long:\n",
        "                param = param.float()                           # Convert to float for noise addition\n",
        "            noise = torch.randn_like(param) * self.noise_scale  # Generate noise based on the noise scale\n",
        "            dp_parameters[name] = param + noise                 # Add noise to the parameters\n",
        "        return dp_parameters\n",
        "\n",
        "\n",
        "    def evaluate(self, parameters: NDArrays, config: Dict[str, Scalar]):\n",
        "        \"\"\"Evaluates the model on the validation data and returns the loss and accuracy.\"\"\"\n",
        "\n",
        "        self.set_parameters(parameters)                         # Set the model parameters received from the server\n",
        "\n",
        "        # Evaluate the model on the validation data\n",
        "        eval_loss, eval_accuracy = test(self.model, self.valloader, self.device)\n",
        "\n",
        "        logger.info(f\"Client {self.client_id} evaluation results: Loss = {eval_loss:.4f}, Accuracy = {eval_accuracy:.4f}\")\n",
        "\n",
        "        return float(eval_loss), len(self.valloader), {\"loss\": eval_loss, \"accuracy\": eval_accuracy}\n",
        "\n",
        "\n",
        "\n",
        "def generate_client_fn(trainloaders, valloaders, num_classes, dataset_choice, epsilon=0.1, delta=1e-5, noise_scale=0.01):\n",
        "    \"\"\"\n",
        "    This function generates a unique initialization function for each client, ensuring that it is dynamically generated.\n",
        "\n",
        "    Arguments:\n",
        "        trainloaders: List of training DataLoaders\n",
        "        valloaders: List of validation DataLoaders\n",
        "        num_classes: Number of output classes for the model\n",
        "        dataset_choice: The dataset being used ('MNIST' or 'CIFAR10').\n",
        "        epsilon: Privacy budget for DP.\n",
        "        delta: Privacy tolerance for DP.\n",
        "        noise_scale: Scale of noise added for DP.\n",
        "\n",
        "    Returns:\n",
        "        A function that initializes a unique FlowerClient for each client.\n",
        "        It is necessary to start the simulation of federated learning environment using FLower framework\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    def client_fn(context: Context):\n",
        "        cid = int(context.node_id) % len(trainloaders)              # Make sure the client ID is within a valid range\n",
        "        logger.info(f\"Initializing client {cid}\")\n",
        "\n",
        "        return FlowerClient(\n",
        "                            trainloader=trainloaders[cid],\n",
        "                            valloader=valloaders[cid],\n",
        "                            num_classes=num_classes,\n",
        "                            dataset_choice=dataset_choice,\n",
        "                            client_id=cid,\n",
        "                            epsilon=epsilon,\n",
        "                            delta=delta,\n",
        "                            noise_scale=noise_scale\n",
        "                        ).to_client()\n",
        "\n",
        "    return client_fn\n"
      ],
      "metadata": {
        "id": "cuAnT7TajtUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Server-Side Operations (server.py):\n",
        "\n",
        "Defines the central server's responsibilities in aggregating model updates from clients using Secure Aggregation, which ensures that sensitive client information remains private. The server also coordinates training sessions and aggregates parameters and evaluation metrics from clients."
      ],
      "metadata": {
        "id": "6KtzMM_njvuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "server.py\n",
        "This script defines the server-side operations in a federated learning setup.\n",
        "Servers aggregate updates from clients, apply secure aggregation techniques to keep sensitive information private and coordinate training sessions.\n",
        "Additionally, both parameters and evaluation metrics can be aggregated using custom functions.\n",
        "'''\n",
        "import torch\n",
        "#from model import get_model, test\n",
        "from typing import Dict, Any, List, Tuple\n",
        "from flwr.common import NDArrays, Scalar, FitRes, Parameters, parameters_to_ndarrays, ndarrays_to_parameters\n",
        "import numpy as np\n",
        "import logging\n",
        "import flwr as fl\n",
        "import os\n",
        "\n",
        "# Logging server operations and issues that occur during the process\n",
        "logging.basicConfig(level=logging.INFO, format='[%(asctime)s] [%(levelname)s] [%(name)s] - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "# Secure Aggregation Function\n",
        "def secure_aggregation(parameters_list: List[NDArrays]) -> Parameters:\n",
        "    \"\"\"\n",
        "    Aggregates model parameters from clients securely.\n",
        "    Arguments:\n",
        "        parameters_list: List of parameter from each client.\n",
        "    Returns:\n",
        "        Parameters: Aggregated parameters after secure aggregation.\n",
        "\n",
        "    In this function, all parameters from all clients are combined.\n",
        "    The idea is to perform this aggregation securely and avoid exposing any client's data individually.\n",
        "    In order to calculate the average value across all participants, we sum the parameters from each client and divide them by the number of clients.\n",
        "    \"\"\"\n",
        "\n",
        "    if not parameters_list or len(parameters_list) == 0:\n",
        "        raise ValueError(\"The parameters list is empty or None.\")           # Handle cases where there are no parameters\n",
        "\n",
        "    aggregated_params = None\n",
        "    num_clients = len(parameters_list)\n",
        "\n",
        "\n",
        "    for param_ndarrays in parameters_list:                                                       # Aggregate parameters from each client\n",
        "        if aggregated_params is None:\n",
        "            aggregated_params = [np.zeros_like(p) for p in param_ndarrays]\n",
        "\n",
        "        aggregated_params = [p1 + p2 for p1, p2 in zip(aggregated_params, param_ndarrays)]       # Sum the parameters across clients\n",
        "\n",
        "    aggregated_params = [p / num_clients for p in aggregated_params]                             # Divide by the number of clients to get the average\n",
        "\n",
        "    return ndarrays_to_parameters(aggregated_params)\n",
        "\n",
        "\n",
        "# Ensure the directory for saving model weights exists\n",
        "weights_dir = './model_weights'\n",
        "if not os.path.exists(weights_dir):\n",
        "    os.makedirs(weights_dir)\n",
        "\n",
        "# After training and aggregating the model parameters in secure_aggregation, save the weights.\n",
        "def save_model_weights(model, server_round):\n",
        "    \"\"\"Save the global model weights after each round.\"\"\"\n",
        "    model_path = os.path.join(weights_dir, f'model_weights_round_{server_round}.pth')\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    logger.info(f\"Model weights saved at {model_path} for round {server_round}\")\n",
        "\n",
        "class SecureAggregationFedAvg(fl.server.strategy.FedAvg):                                         # Custom strategy that includes secure aggregation\n",
        "    def aggregate_fit(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        results: List[Tuple[int, FitRes]],\n",
        "        failures: List[BaseException],\n",
        "        ) -> Tuple[Parameters, Dict[str, Scalar]]:\n",
        "        \"\"\"\n",
        "        Using the secure aggregation instead of the default behavior.\n",
        "\n",
        "        Arguments:\n",
        "            server_round: The current round of federated training.\n",
        "            results: List of client training results.\n",
        "            failures: List of clients that failed during the round.\n",
        "\n",
        "        Returns:\n",
        "            Tuple of aggregated parameters and an empty dictionary for additional information.\n",
        "\n",
        "        As part of this strategy, failures that occur during training rounds are logged, and data aggregation is secure to protect client information.\n",
        "        The method ensures the privacy of the client's contributions.\n",
        "        \"\"\"\n",
        "\n",
        "        if failures:\n",
        "            logger.warning(f\"Round {server_round}: {len(failures)} clients failed.\")                  # Log any client failures\n",
        "\n",
        "        # Convert client parameters to ndarray format for aggregation\n",
        "        parameters_list = [parameters_to_ndarrays(res.parameters) for _, res in results if res.parameters is not None]\n",
        "\n",
        "        if not parameters_list:\n",
        "            raise ValueError(\"The parameters list is empty or None.\")\n",
        "\n",
        "\n",
        "        aggregated_params = secure_aggregation(parameters_list)                                      # Applying secure aggregation to the parameters\n",
        "\n",
        "        logger.info(f\"Round {server_round}: Applied Secure Aggregation on client parameters\")\n",
        "\n",
        "        return aggregated_params, {}\n",
        "\n",
        "\n",
        "# Fonfiguring the training settings per round\n",
        "def get_on_fit_config(config):\n",
        "    \"\"\"\n",
        "    Generates configuration settings for each training round.\n",
        "\n",
        "    Argumants:\n",
        "        config: Configuration object that contains the hyperparameters.\n",
        "\n",
        "    Returns:\n",
        "        A function that generates the configuration for each server round.\n",
        "\n",
        "    The purpose of this function is to customize things like learning rate, weight decay, and number of epochs for each training round.\n",
        "    \"\"\"\n",
        "    def fit_config_fn(server_round: int):\n",
        "        return {\n",
        "\n",
        "            'lr': config['config_fit']['lr'],\n",
        "            'weight_decay': config['config_fit']['weight_decay'],\n",
        "            'momentum': config['config_fit']['momentum'],\n",
        "            'local_epochs': config['config_fit']['local_epochs'],\n",
        "            'batch_size': config['config_fit']['batch_size'],\n",
        "            'clip_value': config['config_fit']['clip_value'],\n",
        "        }\n",
        "\n",
        "    return fit_config_fn\n",
        "\n",
        "\n",
        "def get_evaluate_fn(num_classes, testloader, dataset_choice):\n",
        "    \"\"\"\n",
        "    Generates the evaluation function to test the global model.\n",
        "\n",
        "    Arguments:\n",
        "        num_classes: The number of output classes in the dataset.\n",
        "        testloader: DataLoader for the test dataset.\n",
        "        dataset_choice: The dataset being used ('MNIST' or 'CIFAR10').\n",
        "\n",
        "    Returns:\n",
        "        A function that evaluates the model after each training round.\n",
        "\n",
        "    The purpose of this function is measuring how well the global model is doing after each round.\n",
        "    The latest global model parameters will load, and the global model will test on the test dataset\n",
        "    \"\"\"\n",
        "    def evaluate_fn(server_round: int, parameters: NDArrays, config: Dict[str, Scalar]):\n",
        "\n",
        "        model = get_model(dataset_choice, num_classes)  # Get the model architecture based on the dataset choice\n",
        "\n",
        "        # Load the received parameters into the model's state_dict safely with weights_only=True\n",
        "        state_dict = {k: torch.tensor(v) for k, v in zip(model.state_dict().keys(), parameters)}\n",
        "\n",
        "        # Instead of directly calling load_state_dict, ensure weights_only is applied for safety\n",
        "        model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "        # Evaluate the global model on the test dataset\n",
        "        loss, accuracy = test(model, testloader, device='cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        logger.info(f\"Global model evaluation after round {server_round}: Loss = {loss:.4f}, Accuracy = {accuracy:.4f}\")\n",
        "\n",
        "        return float(loss), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "    return evaluate_fn\n",
        "\n",
        "\n",
        "\n",
        "def fit_metrics_aggregation_fn(metrics_list):                                                          # Aggregation function for training metrics\n",
        "    \"\"\"\n",
        "    Aggregates training metrics (accuracy and loss) from all clients.\n",
        "\n",
        "    Arguments:\n",
        "        metrics_list: List of metrics dictionaries from clients.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary with the average accuracy and loss.\n",
        "\n",
        "    The purpose of this function is to combine the accuracy and loss values from all clients to calculate the global average\n",
        "    and utilize it in providing an overview of the training performance after each round.\n",
        "    \"\"\"\n",
        "    accuracies = [metrics.get(\"accuracy\", 0) for _, metrics in metrics_list]\n",
        "    losses = [metrics.get(\"loss\", 0) for _, metrics in metrics_list]\n",
        "    avg_accuracy = np.mean(accuracies)\n",
        "    avg_loss = np.mean(losses)\n",
        "\n",
        "    return {\"accuracy\": avg_accuracy, \"loss\": avg_loss}\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_metrics_aggregation_fn(metrics_list):                                                      # Aggregation function for evaluation metrics\n",
        "    \"\"\"\n",
        "    Aggregation of the evaluation metrics (accuracy and loss) from all clients.\n",
        "\n",
        "    Arguments:\n",
        "        metrics_list: List of evaluation metrics from clients.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary with the average accuracy and loss.\n",
        "\n",
        "    Similar to the fit_metrics_aggregation_fn, this function aggregates the evaluation metrics\n",
        "    (accuracy and loss) from all clients to provide a global view of the model's performance.\n",
        "    \"\"\"\n",
        "    accuracies = [metrics.get(\"accuracy\", 0) for _, metrics in metrics_list]\n",
        "    losses = [metrics.get(\"loss\", 0) for _, metrics in metrics_list]\n",
        "    avg_accuracy = np.mean(accuracies)\n",
        "    avg_loss = np.mean(losses)\n",
        "\n",
        "    return {\"accuracy\": avg_accuracy, \"loss\": avg_loss}\n"
      ],
      "metadata": {
        "id": "VS5XaQxdj0IV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Federated Learning Orchestration (main.py):\n",
        "\n",
        "The entry point for running the federated learning simulation. This script sets up the clients, dataset, and training strategy, and coordinates multiple rounds of communication between clients and the server, ensuring that results are logged after each round."
      ],
      "metadata": {
        "id": "JDO5vhbIkC3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "\n",
        "multiprocessing.set_start_method('spawn', force=True) # Set multiprocessing start method to avoid os.fork() issues in multithreaded environments\n",
        "'''\n",
        "main.py\n",
        "This script is the entry point for this federated learning simulation using the Flower framework.\n",
        "It sets up the simulation, including the dataset, clients, and training strategy, then runs the federated learning process over multiple rounds.\n",
        "Furthermore, it applies secure aggregation to ensure privacy and logs the results after each round.\n",
        "'''\n",
        "import logging\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "import os\n",
        "import hydra\n",
        "from hydra.core.hydra_config import HydraConfig\n",
        "from omegaconf import DictConfig\n",
        "import flwr as fl\n",
        "#from dataset import prepare_dataset\n",
        "#from client import generate_client_fn\n",
        "#from server import get_on_fit_config, get_evaluate_fn, SecureAggregationFedAvg, fit_metrics_aggregation_fn, evaluate_metrics_aggregation_fn\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "os.environ['HYDRA_FULL_ERROR'] = '1'\n",
        "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
        "\n",
        "\n",
        "# Configuration for logging and displaying the progress of the FL simulation\n",
        "logging.basicConfig(level=logging.INFO, format='[%(asctime)s] [%(levelname)s] [%(name)s] - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "\n",
        "@hydra.main(config_path=\"conf\", config_name=\"base\", version_base=None)\n",
        "def main(cfg):\n",
        "\n",
        "    dataset_choice = input(\"Choose a dataset for FL simulation (MNIST/CIFAR10): \").strip().lower()          # Prompt the user to select a dataset (MNIST or CIFAR10)\n",
        "\n",
        "    if dataset_choice not in [\"mnist\", \"cifar10\"]:                                                          # Validate the dataset choice and ensure it's either MNIST or CIFAR10\n",
        "        raise ValueError(\"Invalid dataset choice. Please choose 'MNIST' or 'CIFAR10'.\")\n",
        "\n",
        "    # Logging the basic configuration parameters\n",
        "    logger.info(f\"num_rounds: {cfg['num_rounds']}, num_clients: {cfg['num_clients']}, batch_size: {cfg['batch_size']}\")\n",
        "    logger.info(f\"num_clients_per_round_fit: {cfg['num_clients_per_round_fit']}, num_clients_per_round_eval: {cfg['num_clients_per_round_eval']}\")\n",
        "    logger.info(f\"Chosen dataset: {dataset_choice.upper()}\")\n",
        "\n",
        "    # Preparation of the dataset by splitting it into client-based loaders for training, validation, and testing\n",
        "    trainloaders, validationloaders, testloader = prepare_dataset(cfg['num_clients'], cfg['batch_size'], dataset_choice)\n",
        "    logger.info(f\"Number of clients: {cfg['num_clients']}, Client 0 dataset size: {len(trainloaders[0].dataset)}\")\n",
        "\n",
        "    # Client function generation to initialize clients using the relevant data and privacy settings\n",
        "    client_fn = generate_client_fn(\n",
        "                                trainloaders,\n",
        "                                validationloaders,\n",
        "                                cfg['num_classes'],\n",
        "                                dataset_choice,\n",
        "                                epsilon=cfg['dp']['epsilon'],\n",
        "                                delta=cfg['dp']['delta'],\n",
        "                                noise_scale=cfg['dp']['noise_scale']\n",
        "                                )\n",
        "\n",
        "\n",
        "    # Dederated learning strategy definition with secure aggregation\n",
        "    strategy = SecureAggregationFedAvg(\n",
        "                fraction_fit=1.0,                                                               # All clients participate in training each round\n",
        "                min_fit_clients=cfg['num_clients'],                                                # Minimum number of clients needed for training\n",
        "                fraction_evaluate=1.0,                                                          # All clients participate in evaluation each round\n",
        "                min_evaluate_clients=cfg['num_clients'],                                           # Minimum number of clients needed for evaluation\n",
        "                min_available_clients=cfg['num_clients'],                                          # Minimum clients that need to be available\n",
        "                on_fit_config_fn=get_on_fit_config(cfg),                                        # Configuration settings for each training round\n",
        "                evaluate_fn=get_evaluate_fn(cfg['num_classes'], testloader, dataset_choice),       # Function to evaluate the global model\n",
        "                fit_metrics_aggregation_fn=fit_metrics_aggregation_fn,                          # Aggregation of training metrics\n",
        "                evaluate_metrics_aggregation_fn=evaluate_metrics_aggregation_fn,                # Aggregation of evaluation metrics\n",
        "    )\n",
        "\n",
        "\n",
        "    # Start point of the the Flower simulation with the defined client function, strategy, and number of rounds\n",
        "    logger.info(\"Starting Flower simulation...\")\n",
        "    '''\n",
        "    history = fl.simulation.start_simulation(\n",
        "        client_fn=client_fn,\n",
        "        num_clients=cfg['num_clients'],\n",
        "        config=fl.server.ServerConfig(num_rounds=cfg['num_rounds']),                               # Number of rounds for the simulation\n",
        "        strategy=strategy,\n",
        "        client_resources={\n",
        "            'num_cpus': cfg['client_resources']['num_cpus'],  # Resource usage handling per client\n",
        "            'num_gpus': cfg['client_resources']['num_gpus']\n",
        "        }\n",
        "    )\n",
        "    '''\n",
        "    # Modify resource allocation here for Colab environment\n",
        "    history = fl.simulation.start_simulation(\n",
        "        client_fn=client_fn,\n",
        "        num_clients=cfg['num_clients'],\n",
        "        config=fl.server.ServerConfig(num_rounds=cfg['num_rounds']),\n",
        "        strategy=strategy,\n",
        "        client_resources={\n",
        "            'num_cpus': cfg['client_resources']['num_cpus'],  # Reduce CPU per client\n",
        "            'num_gpus': cfg['client_resources']['num_gpus']   # Set GPU to 0 if unavailable\n",
        "        }\n",
        "    )\n",
        "\n",
        "\n",
        "    # Saving the results\n",
        "    results_path = Path('./') / 'results.pkl'\n",
        "    with open(str(results_path), 'wb') as h:\n",
        "        pickle.dump({'history': history}, h, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\n",
        "    # Logging a summary of the completed simulation\n",
        "    logger.info(f\"Run finished {cfg['num_rounds']} round(s)\")\n",
        "\n",
        "\n",
        "    # Displaying distributed training loss for each round\n",
        "    if hasattr(history, 'losses_distributed'):\n",
        "        logger.info(\"\\nLoss (Distributed Training):\")\n",
        "        for i, loss in enumerate(history.losses_distributed, 1):\n",
        "            logger.info(f\"    Round {i}: loss = {loss}\")\n",
        "        if len(history.losses_distributed) < cfg['num_rounds']:\n",
        "            missing_rounds = set(range(1, cfg['num_rounds'] + 1)) - set(range(1, len(history.losses_distributed) + 1))\n",
        "            logger.info(f\"    Missing loss data for rounds: {missing_rounds}\")\n",
        "\n",
        "\n",
        "    # Displaying centralized evaluation loss for each round\n",
        "    if hasattr(history, 'losses_centralized'):\n",
        "        logger.info(\"\\nLoss (Centralized Evaluation):\")\n",
        "        for i, loss in enumerate(history.losses_centralized, 0):\n",
        "            logger.info(f\"    Round {i}: {loss[0]:.2f}\")\n",
        "\n",
        "\n",
        "    # Displaying distributed training accuracy for each round\n",
        "    if hasattr(history, 'metrics_distributed'):\n",
        "        logger.info(\"\\nAccuracy (Distributed Training):\")\n",
        "        for i, (round_num, acc) in enumerate(history.metrics_distributed.get(\"accuracy\", []), 1):\n",
        "            logger.info(f\"    Round {i}: {acc * 100:.2f}%\")\n",
        "        if len(history.metrics_distributed.get(\"accuracy\", [])) < cfg['num_rounds']:\n",
        "            missing_rounds = set(range(1, cfg['num_rounds'] + 1)) - set(range(1, len(history.metrics_distributed.get(\"accuracy\", [])) + 1))\n",
        "            logger.info(f\"    Missing accuracy data for rounds: {missing_rounds}\")\n",
        "\n",
        "\n",
        "    # Logging that secure aggregation has been applied in each round\n",
        "    logger.info(\"Secure Aggregation applied in each round\")\n",
        "\n",
        "\n",
        "    # Final logging statement indicating that the simulation has completed\n",
        "    logger.info(\"Flower simulation finished\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "main(cfg)\n"
      ],
      "metadata": {
        "id": "F14NZ_3lkHfB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}